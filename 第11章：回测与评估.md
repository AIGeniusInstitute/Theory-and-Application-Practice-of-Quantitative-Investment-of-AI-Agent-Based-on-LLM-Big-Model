
# 第11章：回测与评估

回测是量化投资策略开发过程中的关键步骤，它允许我们在实际交易之前评估策略的历史表现。然而，回测结果需要谨慎解释，因为它们可能受到前视偏差、过度拟合等问题的影响。本章将探讨如何设计和实施有效的回测系统，以及如何正确评估策略性能。

## 11.1 回测系统设计

### 11.1.1 事件驱动回测框架

事件驱动回测框架是一种灵活且高效的回测方法，它模拟了市场数据到达和交易执行的实际过程。以下是一个简单的事件驱动回测框架示例：

```python
import pandas as pd
import numpy as np
from collections import deque

class EventDrivenBacktester:
    def __init__(self, data, initial_capital=100000):
        self.data = data
        self.events = deque()
        self.current_time = None
        self.positions = {}
        self.cash = initial_capital
        self.portfolio_value = initial_capital
        self.trades = []

    def run(self):
        for timestamp, row in self.data.iterrows():
            self.current_time = timestamp
            self.update_portfolio(row)
            self.handle_events(row)
            self.generate_signals(row)

    def update_portfolio(self, row):
        self.portfolio_value = self.cash
        for symbol, quantity in self.positions.items():
            self.portfolio_value += quantity * row[symbol]

    def handle_events(self, row):
        while self.events and self.events[0][0] <= self.current_time:
            event_time, event_type, event_data = self.events.popleft()
            if event_type == 'ORDER':
                self.execute_order(event_data, row)

    def generate_signals(self, row):
        # 这里实现你的交易信号生成逻辑
        pass

    def place_order(self, symbol, quantity, order_type='MARKET'):
        order = {
            'symbol': symbol,
            'quantity': quantity,
            'type': order_type
        }
        self.events.append((self.current_time, 'ORDER', order))

    def execute_order(self, order, row):
        symbol = order['symbol']
        quantity = order['quantity']
        price = row[symbol]
        
        cost = quantity * price
        if cost > self.cash and quantity > 0:
            return  # 资金不足，无法执行订单
        
        self.cash -= cost
        self.positions[symbol] = self.positions.get(symbol, 0) + quantity
        
        self.trades.append({
            'time': self.current_time,
            'symbol': symbol,
            'quantity': quantity,
            'price': price
        })

    def get_results(self):
        returns = pd.Series(self.get_portfolio_values()).pct_change()
        sharpe_ratio = np.sqrt(252) * returns.mean() / returns.std()
        max_drawdown = (self.get_portfolio_values().cummax() - self.get_portfolio_values()).max()
        
        return {
            'final_portfolio_value': self.portfolio_value,
            'returns': returns,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'trades': pd.DataFrame(self.trades)
        }

    def get_portfolio_values(self):
        portfolio_values = []
        for timestamp, row in self.data.iterrows():
            value = self.cash
            for symbol, quantity in self.positions.items():
                value += quantity * row[symbol]
            portfolio_values.append(value)
        return pd.Series(portfolio_values, index=self.data.index)

# 使用示例
np.random.seed(42)
dates = pd.date_range(start='2020-01-01', end='2020-12-31', freq='D')
data = pd.DataFrame({
    'AAPL': np.random.normal(loc=0.0005, scale=0.02, size=len(dates)).cumsum() + 100,
    'GOOGL': np.random.normal(loc=0.0007, scale=0.02, size=len(dates)).cumsum() + 150
}, index=dates)

class SimpleMovingAverageCrossover(EventDrivenBacktester):
    def __init__(self, data, initial_capital=100000, short_window=50, long_window=200):
        super().__init__(data, initial_capital)
        self.short_window = short_window
        self.long_window = long_window

    def generate_signals(self, row):
        for symbol in self.data.columns:
            short_ma = self.data[symbol].rolling(self.short_window).mean().iloc[-1]
            long_ma = self.data[symbol].rolling(self.long_window).mean().iloc[-1]
            
            if short_ma > long_ma and symbol not in self.positions:
                self.place_order(symbol, 100)  # 买入
            elif short_ma < long_ma and symbol in self.positions:
                self.place_order(symbol, -self.positions[symbol])  # 卖出全部持仓

backtester = SimpleMovingAverageCrossover(data)
backtester.run()
results = backtester.get_results()

print(f"Final Portfolio Value: ${results['final_portfolio_value']:.2f}")
print(f"Sharpe Ratio: {results['sharpe_ratio']:.2f}")
print(f"Max Drawdown: {results['max_drawdown']:.2%}")
print("\nTrade Summary:")
print(results['trades'])

# 绘制投资组合价值随时间的变化
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
backtester.get_portfolio_values().plot()
plt.title('Portfolio Value Over Time')
plt.xlabel('Date')
plt.ylabel('Portfolio Value ($)')
plt.show()
```

这个事件驱动回测框架的主要特点包括：

1. 灵活性：可以轻松处理多种类型的事件，如市场数据更新、订单执行等。

2. 真实性：更接近实际交易过程，可以模拟订单延迟、部分成交等情况。

3. 可扩展性：易于添加新的事件类型和处理逻辑。

4. 效率：通过事件队列管理，避免不必要的计算。

在实际应用中，你可能需要考虑以下几点来进一步改进这个框架：

1. 多数据源支持：处理来自不同来源的数据，如实时行情、基本面数据等。

2. 订单类型：支持更多订单类型，如限价单、止损单等。

3. 滑点模型：实现更复杂的滑点模型，以更好地模拟实际交易成本。

4. 交易量限制：考虑市场流动性，实现基于交易量的限制。

5. 多线程支持：对于复杂的策略，考虑使用多线程来提高回测速度。

6. 风险管理：集成风险管理模块，如动态止损、风险敞口控制等。

7. 报告生成：自动生成详细的回测报告，包括各种性能指标和图表。

8. 参数优化：集成参数优化功能，如网格搜索或遗传算法。

9. 市场影响模型：考虑大额交易对市场价格的影响。

10. 多资产支持：扩展框架以支持多资产类别和跨市场交易。

### 11.1.2 数据管理与同步

在回测过程中，有效的数据管理和同步至关重要，特别是当处理多个数据源或不同频率的数据时。以下是一个改进的回测框架，重点关注数据管理和同步：

```python
import pandas as pd
import numpy as np
from collections import deque
import matplotlib.pyplot as plt

class DataManager:
    def __init__(self):
        self.data_sources = {}

    def add_data_source(self, name, data):
        self.data_sources[name] = data.sort_index()

    def get_latest_data(self, timestamp):
        latest_data = {}
        for name, data in self.data_sources.items():
            latest_data[name] = data.loc[:timestamp].iloc[-1]
        return latest_data

class Event:
    def __init__(self, event_type, timestamp, data):
        self.type = event_type
        self.timestamp = timestamp
        self.data = data

class EventQueue:
    def __init__(self):
        self.queue = deque()

    def add(self, event):
        self.queue.append(event)
        self.queue = deque(sorted(self.queue, key=lambda x: x.timestamp))

    def pop(self):
        return self.queue.popleft() if self.queue else None

    def peek(self):
        return self.queue[0] if self.queue else None

class ImprovedBacktester:
    def __init__(self, initial_capital=100000):
        self.data_manager = DataManager()
        self.event_queue = EventQueue()
        self.current_time = None
        self.positions = {}
        self.cash = initial_capital
        self.portfolio_value = initial_capital
        self.trades = []
        self.portfolio_history = []

    def add_data(self, name, data):
        self.data_manager.add_data_source(name, data)
        for timestamp in data.index:
            self.event_queue.add(Event('MARKET_DATA', timestamp, {'source': name}))

    def run(self):
        while True:
            event = self.event_queue.pop()
            if event is None:
                break

            self.current_time = event.timestamp
            if event.type == 'MARKET_DATA':
                self.handle_market_data(event)
            elif event.type == 'ORDER':
                self.handle_order(event.data)

            self.update_portfolio()
            self.generate_signals()

    def handle_market_data(self, event):
        latest_data = self.data_manager.get_latest_data(self.current_time)
        self.process_market_data(latest_data)

    def process_market_data(self, data):
        # 在这里实现处理市场数据的逻辑
        pass

    def handle_order(self, order):
        symbol = order['symbol']
        quantity = order['quantity']
        latest_data = self.data_manager.get_latest_data(self.current_time)
        price = latest_data[symbol]

        cost = quantity * price
        if cost > self.cash and quantity > 0:
            return  # 资金不足，无法执行订单

        self.cash -= cost
        self.positions[symbol] = self.positions.get(symbol, 0) + quantity

        self.trades.append({
            'time': self.current_time,
            'symbol': symbol,
            'quantity': quantity,
            'price': price
        })

    def update_portfolio(self):
        latest_data = self.data_manager.get_latest_data(self.current_time)
        self.portfolio_value = self.cash
        for symbol, quantity in self.positions.items():
            self.portfolio_value += quantity * latest_data[symbol]

        self.portfolio_history.append({
            'time': self.current_time,
            'value': self.portfolio_value
        })

    def generate_signals(self):
        # 在这里实现生成交易信号的逻辑
        pass

    def place_order(self, symbol, quantity, order_type='MARKET'):
        order = {
            'symbol': symbol,
            'quantity': quantity,
            'type': order_type
        }
        self.event_queue.add(Event('ORDER', self.current_time, order))

    def get_results(self):
        portfolio_values = pd.DataFrame(self.portfolio_history).set_index('time')['value']
        returns = portfolio_values.pct_change()
        sharpe_ratio = np.sqrt(252) * returns.mean() / returns.std()
        max_drawdown = (portfolio_values.cummax() - portfolio_values).max() / portfolio_values.cummax()

        return {
            'final_portfolio_value': self.portfolio_value,
            'returns': returns,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'trades': pd.DataFrame(self.trades)
        }

    def plot_portfolio_value(self):
        portfolio_values = pd.DataFrame(self.portfolio_history).set_index('time')['value']
        plt.figure(figsize=(12, 6))
        portfolio_values.plot()
        plt.title('Portfolio Value Over Time')
        plt.xlabel('Date')
        plt.ylabel('Portfolio Value ($)')
        plt.show()

class MovingAverageCrossoverStrategy(ImprovedBacktester):
    def __init__(self, initial_capital=100000, short_window=50, long_window=200):
        super().__init__(initial_capital)
        self.short_window = short_window
        self.long_window = long_window

    def process_market_data(self, data):
        for symbol, price in data.items():
            if symbol not in self.data_manager.data_sources:
                continue

            prices = self.data_manager.data_sources[symbol].loc[:self.current_time]
            if len(prices) >= self.long_window:
                short_ma = prices.rolling(self.short_window).mean().iloc[-1]
                long_ma = prices.rolling(self.long_window).mean().iloc[-1]

                current_position = self.positions.get(symbol, 0)
                if short_ma > long_ma and current_position == 0:
                    self.place_order(symbol, 100)  # 买入
                elif short_ma < long_ma and current_position > 0:
                    self.place_order(symbol, -current_position)  # 卖出全部持仓

# 使用示例
np.random.seed(42)
dates = pd.date_range(start='2020-01-01', end='2020-12-31', freq='D')
data_aapl = pd.Series(np.random.normal(loc=0.0005, scale=0.02, size=len(dates)).cumsum() + 100, index=dates, name='AAPL')
data_googl = pd.Series(np.random.normal(loc=0.0007, scale=0.02, size=len(dates)).cumsum() + 150, index=dates, name='GOOGL')

backtester = MovingAverageCrossoverStrategy()
backtester.add_data('AAPL', data_aapl)
backtester.add_data('GOOGL', data_googl)
backtester.run()

results = backtester.get_results()

print(f"Final Portfolio Value: ${results['final_portfolio_value']:.2f}")
print(f"Sharpe Ratio: {results['sharpe_ratio']:.2f}")
print(f"Max Drawdown: {results['max_drawdown']:.2%}")
print("\nTrade Summary:")
print(results['trades'])

backtester.plot_portfolio_value()
```

这个改进的回测框架具有以下特点：

1. 数据管理：使用`DataManager`类管理多个数据源，支持不同频率的数据。

2. 事件队列：使用`EventQueue`类管理和同步不同类型的事件。

3. 模块化设计：将数据处理、订单执行和信号生成等功能分离，提高了代码的可维护性。

4. 灵活性：易于扩展以支持新的数据源、事件类型和策略。

5. 性能：通过事件驱动的方式，避免了不必要的计算和数据访问。

在实际应用中，你可能还需要考虑以下几点来进一步改进这个框架：

1. 数据预处理：添加数据清洗、对齐和插值等预处理功能。

2. 缓存机制：实现智能缓存，以提高频繁访问的数据的检索速度。

3. 实时数据模拟：支持模拟实时数据流，以测试策略在实时环境中的表现。

4. 多线程/多进程：对于计算密集型任务，考虑使用并行处理。

5. 数据持久化：实现数据的序列化和反序列化，支持长时间运行的回测。

6. 风险管理：集成更复杂的风险管理模块，如VaR计算、压力测试等。

7. 性能分析：添加详细的性能分析工具，如归因分析、滚动夏普比率等。

8. 可视化增强：实现更丰富的可视化功能，如交易图表、风险指标仪表板等。

9. 参数优化：集成参数优化框架，如网格搜索、遗传算法或贝叶斯优化。

10. 市场微观结构：模拟订单簿动态，以更真实地反映市场微观结构。

### 11.1.3 交易成本模型

准确的交易成本模型对于回测的真实性至关重要。以下是一个包含更复杂交易成本模型的回测框架示例：

```python
import pandas as pd
import numpy as np
from collections import deque
import matplotlib.pyplot as plt

class TradingCostsModel:
    def __init__(self, commission_rate=0.001, slippage_std=0.0005, market_impact_factor=1e-6):
        self.commission_rate = commission_rate
        self.slippage_std = slippage_std
        self.market_impact_factor = market_impact_factor

    def calculate_costs(self, price, quantity, average_volume):
        commission = abs(price * quantity * self.commission_rate)
        slippage = abs(price * quantity * np.random.normal(0, self.slippage_std))
        market_impact = price * abs(quantity) * self.market_impact_factor * (abs(quantity) / average_volume)
        total_cost = commission + slippage + market_impact
        return total_cost, {'commission': commission, 'slippage': slippage, 'market_impact': market_impact}

class ImprovedBacktesterWithCosts(ImprovedBacktester):
    def __init__(self, initial_capital=100000):
        super().__init__(initial_capital)
        self.costs_model = TradingCostsModel()
        self.total_costs = 0
        self.cost_breakdown = {'commission': 0, 'slippage': 0, 'market_impact': 0}

    def handle_order(self, order):
        symbol = order['symbol']
        quantity = order['quantity']
        latest_data = self.data_manager.get_latest_data(self.current_time)
        price = latest_data[symbol]

        # 获取平均成交量（这里使用过去20天的平均值作为示例）
        volume_history = self.data_manager.data_sources[f"{symbol}_volume"].loc[:self.current_time]
        average_volume = volume_history.rolling(20).mean().iloc[-1]

        # 计算交易成本
        cost, cost_breakdown = self.costs_model.calculate_costs(price, quantity, average_volume)

        total_amount = quantity * price + cost
        if total_amount > self.cash and quantity > 0:
            return  # 资金不足，无法执行订单

        self.cash -= total_amount
        self.positions[symbol] = self.positions.get(symbol, 0) + quantity

        # 更新总成本和成本明细
        self.total_costs += cost
        for cost_type, amount in cost_breakdown.items():
            self.cost_breakdown[cost_type] += amount

        self.trades.append({
            'time': self.current_time,
            'symbol': symbol,
            'quantity': quantity,
            'price': price,
            'cost': cost
        })

    def get_results(self):
        results = super().get_results()
        results['total_costs'] = self.total_costs
        results['cost_breakdown'] = self.cost_breakdown
        return results

class MovingAverageCrossoverStrategyWithCosts(ImprovedBacktesterWithCosts):
    def __init__(self, initial_capital=100000, short_window=50, long_window=200):
        super().__init__(initial_capital)
        self.short_window = short_window
        self.long_window = long_window

    def process_market_data(self, data):
        for symbol, price in data.items():
            if symbol not in self.data_manager.data_sources or f"{symbol}_volume" not in self.data_manager.data_sources:
                continue

            prices = self.data_manager.data_sources[symbol].loc[:self.current_time]
            if len(prices) >= self.long_window:
                short_ma = prices.rolling(self.short_window).mean().iloc[-1]
                long_ma = prices.rolling(self.long_window).mean().iloc[-1]

                current_position = self.positions.get(symbol, 0)
                if short_ma > long_ma and current_position == 0:
                    self.place_order(symbol, 100)  # 买入
                elif short_ma < long_ma and current_position > 0:
                    self.place_order(symbol, -current_position)  # 卖出全部持仓

# 使用示例
np.random.seed(42)
dates = pd.date_range(start='2020-01-01', end='2020-12-31', freq='D')
data_aapl = pd.Series(np.random.normal(loc=0.0005, scale=0.02, size=len(dates)).cumsum() + 100, index=dates, name='AAPL')
data_googl = pd.Series(np.random.normal(loc=0.0007, scale=0.02, size=len(dates)).cumsum() + 150, index=dates, name='GOOGL')
volume_aapl = pd.Series(np.random.randint(1000000, 5000000, size=len(dates)), index=dates, name='AAPL_volume')
volume_googl = pd.Series(np.random.randint(500000, 2000000, size=len(dates)), index=dates, name='GOOGL_volume')

backtester = MovingAverageCrossoverStrategyWithCosts()
backtester.add_data('AAPL', data_aapl)
backtester.add_data('GOOGL', data_googl)
backtester.add_data('AAPL_volume', volume_aapl)
backtester.add_data('GOOGL_volume', volume_googl)
backtester.run()

results = backtester.get_results()

print(f"Final Portfolio Value: ${results['final_portfolio_value']:.2f}")
print(f"Sharpe Ratio: {results['sharpe_ratio']:.2f}")
print(f"Max Drawdown: {results['max_drawdown']:.2%}")
print(f"Total Trading Costs: ${results['total_costs']:.2f}")
print("\nCost Breakdown:")
for cost_type, amount in results['cost_breakdown'].items():
    print(f"{cost_type.capitalize()}: ${amount:.2f}")
print("\nTrade Summary:")
print(results['trades'])

backtester.plot_portfolio_value()
```

这个改进的回测框架包含了更复杂的交易成本模型，具有以下特点：

1. 多维度成本：考虑了佣金、滑点和市场影响三个方面的交易成本。

2. 动态滑点：使用随机滑点模型，更真实地模拟市场条件。

3. 市场影响：基于交易量相对于平均成交量的比例计算市场影响成本。

4. 成本明细：提供详细的成本breakdown，有助于分析不同类型成本的影响。

5. 灵活性：易于扩展以支持更复杂的成本模型或不同资产类别的特定成本结构。

在实际应用中，你可能还需要考虑以下几点来进一步改进交易成本模型：

1. 分层佣金结构：实现更复杂的佣金结构，如阶梯式佣金或固定+可变佣金。

2. 流动性相关滑点：基于市场深度和订单规模动态调整滑点。

3. 非线性市场影响：使用非线性函数模拟大额订单的市场影响。

4. 时变成本模型：根据市场条件（如波动性）动态调整成本参数。

5. 交易对手风险：模拟交易对手风险带来的额外成本。

6. 融资成本：考虑保证金交易的融资成本。

7. 税收模型：加入适用的税收计算。

8. 交易延迟：模拟订单执行延迟对成本的影响。

9. 做市商价差：对于某些资产类别，考虑做市商价差的影响。

10. 批量折扣：实现大额交易的批量折扣机制。

11. 交易所费用：加入特定交易所的费用结构。

12. 货币兑换成本：对于跨币种交易，考虑货币兑换成本。

13. 结算和清算费用：加入与结算和清算相关的费用。

14. 报价效应：模拟大额订单对市场报价的影响。

15. 流动性事件：模拟特殊市场事件（如流动性枯竭）对交易成本的影响。

通过实现这些改进，我们可以创建一个更加真实和全面的交易成本模型，从而提高回测结果的可靠性和实用性。

## 11.2 性能指标计算

准确的性能指标计算对于评估交易策略的效果至关重要。以下是一个包含多种常用性能指标的计算模块：

```python
import numpy as np
import pandas as pd
from scipy import stats

class PerformanceMetrics:
    def __init__(self, returns, risk_free_rate=0.02):
        self.returns = returns
        self.risk_free_rate = risk_free_rate

    def calculate_cumulative_returns(self):
        return (1 + self.returns).cumprod() - 1

    def calculate_total_return(self):
        return self.calculate_cumulative_returns().iloc[-1]

    def calculate_annualized_return(self):
        total_return = self.calculate_total_return()
        num_years = len(self.returns) / 252  # 假设252个交易日
        return (1 + total_return) ** (1 / num_years) - 1

    def calculate_annualized_volatility(self):
        return self.returns.std() * np.sqrt(252)

    def calculate_sharpe_ratio(self):
        excess_returns = self.returns - self.risk_free_rate / 252
        return np.sqrt(252) * excess_returns.mean() / excess_returns.std()

    def calculate_sortino_ratio(self):
        excess_returns = self.returns - self.risk_free_rate / 252
        downside_returns = excess_returns[excess_returns < 0]
        downside_deviation = np.sqrt(np.mean(downside_returns**2))
        return np.sqrt(252) * excess_returns.mean() / downside_deviation

    def calculate_max_drawdown(self):
        cumulative_returns = self.calculate_cumulative_returns()
        peak = cumulative_returns.cummax()
        drawdown = (cumulative_returns - peak) / peak
        return drawdown.min()

    def calculate_calmar_ratio(self):
        return self.calculate_annualized_return() / abs(self.calculate_max_drawdown())

    def calculate_omega_ratio(self, threshold=0):
        returns_above_threshold = self.returns[self.returns > threshold]
        returns_below_threshold = self.returns[self.returns <= threshold]
        return returns_above_threshold.sum() / abs(returns_below_threshold.sum())

    def calculate_information_ratio(self, benchmark_returns):
        active_returns = self.returns - benchmark_returns
        return np.sqrt(252) * active_returns.mean() / active_returns.std()

    def calculate_beta(self, market_returns):
        covariance = np.cov(self.returns, market_returns)[0][1]
        market_variance = np.var(market_returns)
        return covariance / market_variance

    def calculate_alpha(self, market_returns):
        beta = self.calculate_beta(market_returns)
        return self.returns.mean() - (self.risk_free_rate / 252 + beta * (market_returns.mean() - self.risk_free_rate / 252))

    def calculate_var(self, confidence_level=0.95):
        return np.percentile(self.returns, (1 - confidence_level) * 100)

    def calculate_cvar(self, confidence_level=0.95):
        var = self.calculate_var(confidence_level)
        return self.returns[self.returns <= var].mean()

    def calculate_skewness(self):
        return stats.skew(self.returns)

    def calculate_kurtosis(self):
        return stats.kurtosis(self.returns)

    def calculate_profit_factor(self):
        positive_returns = self.returns[self.returns > 0].sum()
        negative_returns = abs(self.returns[self.returns < 0].sum())
        return positive_returns / negative_returns

    def calculate_gain_to_pain_ratio(self):
        return self.returns.sum() / abs(self.returns[self.returns < 0].sum())

    def get_all_metrics(self, benchmark_returns=None, market_returns=None):
        metrics = {
            'Total Return': self.calculate_total_return(),
            'Annualized Return': self.calculate_annualized_return(),
            'Annualized Volatility': self.calculate_annualized_volatility(),
            'Sharpe Ratio': self.calculate_sharpe_ratio(),
            'Sortino Ratio': self.calculate_sortino_ratio(),
            'Max Drawdown': self.calculate_max_drawdown(),
            'Calmar Ratio': self.calculate_calmar_ratio(),
            'Omega Ratio': self.calculate_omega_ratio(),
            'VaR (95%)': self.calculate_var(),
            'CVaR (95%)': self.calculate_cvar(),
            'Skewness': self.calculate_skewness(),
            'Kurtosis': self.calculate_kurtosis(),
            'Profit Factor': self.calculate_profit_factor(),
            'Gain to Pain Ratio': self.calculate_gain_to_pain_ratio()
        }
        
        if benchmark_returns is not None:
            metrics['Information Ratio'] = self.calculate_information_ratio(benchmark_returns)
        
        if market_returns is not None:
            metrics['Beta'] = self.calculate_beta(market_returns)
            metrics['Alpha'] = self.calculate_alpha(market_returns)
        
        return metrics

# 使用示例
np.random.seed(42)
dates = pd.date_range(start='2020-01-01', end='2020-12-31', freq='D')
strategy_returns = pd.Series(np.random.normal(0.0005, 0.01, len(dates)), index=dates)
benchmark_returns = pd.Series(np.random.normal(0.0003, 0.02, len(dates)), index=dates)
market_returns = pd.Series(np.random.normal(0.0004, 0.015, len(dates)), index=dates)

metrics = PerformanceMetrics(strategy_returns)
all_metrics = metrics.get_all_metrics(benchmark_returns, market_returns)

for metric, value in all_metrics.items():
    print(f"{metric}: {value:.4f}")

# 可视化累积收益
cumulative_returns = metrics.calculate_cumulative_returns()
plt.figure(figsize=(12, 6))
cumulative_returns.plot()
plt.title('Cumulative Returns')
plt.xlabel('Date')
plt.ylabel('Cumulative Returns')
plt.show()
```

这个性能指标计算模块包含了多个常用的指标，包括：

1. 总收益和年化收益
2. 年化波动率
3. 夏普比率和索提诺比率
4. 最大回撤和卡玛比率
5. Omega比率
6. 信息比率（相对于基准）
7. Beta和Alpha（相对于市场）
8. 风险价值（VaR）和条件风险价值（CVaR）
9. 偏度和峰度
10. 盈利因子和收益痛苦比

在实际应用中，你可能还需要考虑以下几点来进一步改进性能指标计算：

1. 滚动指标：计算滚动窗口的指标，以观察策略性能的时间变化。

2. 统计显著性：对关键指标进行统计显著性测试。

3. 回撤分析：提供更详细的回撤分析，如回撤持续时间、回撤恢复时间等。

4. 交易统计：加入更多与交易相关的统计，如胜率、平均盈亏比等。

5. 风险调整收益：实现更多的风险调整收益指标，如特雷诺比率、詹森阿尔法等。

6. 基于子期间的分析：按月、季度、年度等时间段分别计算指标。

7. 压力期分析：识别和分析策略在市场压力期的表现。

8. 归因分析：实现详细的收益归因分析。

9. 情景分析：在不同市场情景下评估策略性能。

10. 可视化增强：实现更丰富的可视化功能，如风险收益散点图、滚动性能图表等。

通过实现这些改进，我们可以获得更全面和深入的策略性能评估，从而做出更明智的投资决策。

## 11.3 统计显著性检验

统计显著性检验是评估策略性能可靠性的重要工具。以下是一个包含多种统计检验的模块，用于评估策略性能的统计显著性：

```python
import numpy as np
import pandas as pd
from scipy import stats
from statsmodels.stats.diagnostic import acorr_ljungbox
from arch import arch_model

class StatisticalTests:
    def __init__(self, strategy_returns, benchmark_returns=None):
        self.strategy_returns = strategy_returns
        self.benchmark_returns = benchmark_returns

    def t_test_mean_return(self):
        """
        对策略收益率进行t检验，检验其均值是否显著不为零
        """
        t_stat, p_value = stats.ttest_1samp(self.strategy_returns, 0)
        return {
            'test': 't-test for mean return',
            't_statistic': t_stat,
            'p_value': p_value
        }

    def wilcoxon_signed_rank_test(self):
        """
        使用Wilcoxon符号秩检验，检验策略收益率的中位数是否显著不为零
        """
        statistic, p_value = stats.wilcoxon(self.strategy_returns)
        return {
            'test': 'Wilcoxon signed-rank test',
            'statistic': statistic,
            'p_value': p_value
        }

    def jarque_bera_test(self):
        """
        Jarque-Bera测试，检验策略收益率是否服从正态分布
        """
        statistic, p_value = stats.jarque_bera(self.strategy_returns)
        return {
            'test': 'Jarque-Bera test',
            'statistic': statistic,
            'p_value': p_value
        }

    def ljung_box_test(self, lags=10):
        """
        Ljung-Box测试，检验策略收益率是否存在自相关性
        """
        statistic, p_value = acorr_ljungbox(self.strategy_returns, lags=[lags])
        return {
            'test': 'Ljung-Box test',
            'statistic': statistic[0],
            'p_value': p_value[0]
        }

    def engle_arch_test(self, lags=10):
        """
        Engle's ARCH测试，检验策略收益率是否存在ARCH效应
        """
        _, p_value, _ = arch_model(self.strategy_returns).fit(disp='off').arch_lm_test(lags)
        return {
            'test': "Engle's ARCH test",
            'p_value': p_value
        }

    def paired_t_test(self):
        """
        配对t检验，比较策略收益率与基准收益率
        """
        if self.benchmark_returns is None:
            return None
        t_stat, p_value = stats.ttest_rel(self.strategy_returns, self.benchmark_returns)
        return {
            'test': 'Paired t-test',
            't_statistic': t_stat,
            'p_value': p_value
        }

    def mann_whitney_u_test(self):
        """
        Mann-Whitney U检验，比较策略收益率与基准收益率的分布
        """
        if self.benchmark_returns is None:
            return None
        statistic, p_value = stats.mannwhitneyu(self.strategy_returns, self.benchmark_returns)
        return {
            'test': 'Mann-Whitney U test',
            'statistic': statistic,
            'p_value': p_value
        }

    def run_all_tests(self):
        tests = [
            self.t_test_mean_return(),
            self.wilcoxon_signed_rank_test(),
            self.jarque_bera_test(),
            self.ljung_box_test(),
            self.engle_arch_test()
        ]
        
        if self.benchmark_returns is not None:
            tests.extend([
                self.paired_t_test(),
                self.mann_whitney_u_test()
            ])
        
        return tests

# 使用示例
np.random.seed(42)
dates = pd.date_range(start='2020-01-01', end='2020-12-31', freq='D')
strategy_returns = pd.Series(np.random.normal(0.0005, 0.01, len(dates)), index=dates)
benchmark_returns = pd.Series(np.random.normal(0.0003, 0.02, len(dates)), index=dates)

statistical_tests = StatisticalTests(strategy_returns, benchmark_returns)
test_results = statistical_tests.run_all_tests()

for result in test_results:
    print(f"\n{result['test']}:")
    for key, value in result.items():
        if key != 'test':
            print(f"  {key}: {value:.4f}")
```

这个统计检验模块包含了多个常用的统计检验，包括：

1. t检验：检验策略收益率的均值是否显著不为零。
2. Wilcoxon符号秩检验：非参数检验，检验策略收益率的中位数是否显著不为零。
3. Jarque-Bera检验：检验策略收益率是否服从正态分布。
4. Ljung-Box检验：检验策略收益率是否存在自相关性。
5. Engle's ARCH检验：检验策略收益率是否存在ARCH效应（波动率聚集）。
6. 配对t检验：比较策略收益率与基准收益率的均值差异。
7. Mann-Whitney U检验：非参数检验，比较策略收益率与基准收益率的分布差异。

在实际应用中，你可能还需要考虑以下几点来进一步改进统计显著性检验：

1. 多重检验校正：当进行多个统计检验时，使用如Bonferroni校正或False Discovery Rate (FDR)控制来调整p值。

2. 样本外测试：实现样本外测试，以评估策略在未见过的数据上的表现。

3. 交叉验证：使用交叉验证技术来评估策略的稳健性。

4. 自举法（Bootstrap）：使用自举法来估计统计量的置信区间。

5. 时间序列分解：对策略收益进行时间序列分解，分别分析趋势、季节性和残差成分。

6. 协整检验：对于配对交易策略，实现协整检验。

7. 单位根检验：实现单位根检验，如增广迪基-富勒检验（ADF test），以检查时间序列的平稳性。

8. Granger因果检验：检验不同变量之间的因果关系。

9. 结构性断裂检验：检测时间序列中的结构性变化。

10. 非线性依赖性检验：实现如BDS检验等，用于检测非线性依赖性。

以下是一些额外的统计检验的实现示例：

```python
from statsmodels.tsa.stattools import adfuller, coint
from statsmodels.stats.multitest import multipletests
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import grangercausalitytests
from statsmodels.tsa.stattools import bds

class AdvancedStatisticalTests(StatisticalTests):
    def __init__(self, strategy_returns, benchmark_returns=None):
        super().__init__(strategy_returns, benchmark_returns)

    def adf_test(self):
        """
        增广迪基-富勒检验，检验时间序列的平稳性
        """
        result = adfuller(self.strategy_returns)
        return {
            'test': 'Augmented Dickey-Fuller test',
            'adf_statistic': result[0],
            'p_value': result[1],
            'critical_values': result[4]
        }

    def cointegration_test(self):
        """
        协整检验，检验策略收益与基准收益是否协整
        """
        if self.benchmark_returns is None:
            return None
        result = coint(self.strategy_returns, self.benchmark_returns)
        return {
            'test': 'Cointegration test',
            'cointegration_statistic': result[0],
            'p_value': result[1],
            'critical_values': result[2]
        }

    def granger_causality_test(self, maxlag=5):
        """
        Granger因果检验
        """
        if self.benchmark_returns is None:
            return None
        data = pd.concat([self.strategy_returns, self.benchmark_returns], axis=1)
        result = grangercausalitytests(data, maxlag=maxlag, verbose=False)
        return {
            'test': 'Granger causality test',
            'results': {lag: {'ssr_ftest': (res[0]['ssr_ftest'][0], res[0]['ssr_ftest'][1])} for lag, res in result.items()}
        }

    def bds_test(self, max_dim=5):
        """
        BDS检验，用于检测非线性依赖性
        """
        results = []
        for dim in range(2, max_dim + 1):
            stat, p_value = bds(self.strategy_returns, max_dim=dim)
            results.append({'dimension': dim, 'statistic': stat, 'p_value': p_value})
        return {
            'test': 'BDS test',
            'results': results
        }

    def run_advanced_tests(self):
        tests = [
            self.adf_test(),
            self.cointegration_test(),
            self.granger_causality_test(),
            self.bds_test()
        ]
        return [test for test in tests if test is not None]

# 使用示例
advanced_tests = AdvancedStatisticalTests(strategy_returns, benchmark_returns)
advanced_test_results = advanced_tests.run_advanced_tests()

for result in advanced_test_results:
    print(f"\n{result['test']}:")
    if isinstance(result['results'], list):
        for item in result['results']:
            print(f"  Dimension {item['dimension']}:")
            print(f"    Statistic: {item['statistic']:.4f}")
            print(f"    p-value: {item['p_value']:.4f}")
    elif isinstance(result['results'], dict):
        for lag, values in result['results'].items():
            print(f"  Lag {lag}:")
            print(f"    F-statistic: {values['ssr_ftest'][0]:.4f}")
            print(f"    p-value: {values['ssr_ftest'][1]:.4f}")
    else:
        for key, value in result.items():
            if key != 'test':
                if isinstance(value, dict):
                    print(f"  {key}:")
                    for sub_key, sub_value in value.items():
                        print(f"    {sub_key}: {sub_value:.4f}")
                else:
                    print(f"  {key}: {value:.4f}")
```

这些高级统计检验可以提供更深入的策略分析：

1. ADF检验可以帮助确定策略收益是否是平稳的，这对于许多统计模型的应用是重要的前提。

2. 协整检验可以帮助识别长期均衡关系，这对于配对交易策略特别有用。

3. Granger因果检验可以帮助理解策略收益与基准收益之间的领先-滞后关系。

4. BDS检验可以检测时间序列中的非线性依赖性，这对于识别复杂的市场动态很有帮助。

通过结合这些基本和高级的统计检验，我们可以对策略的性能进行更全面和严格的评估，从而增强对策略可靠性和稳健性的信心。然而，需要注意的是，这些统计检验应该与其他定性和定量分析方法结合使用，以获得对策略的全面理解。

## 11.4 鲁棒性分析

鲁棒性分析是评估量化交易策略稳定性和可靠性的重要步骤。它帮助我们了解策略在不同市场条件下的表现，以及对参数变化的敏感程度。以下是一个鲁棒性分析模块的示例：

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from itertools import product
from concurrent.futures import ProcessPoolExecutor

class RobustnessAnalysis:
    def __init__(self, strategy_class, data, initial_parameters):
        self.strategy_class = strategy_class
        self.data = data
        self.initial_parameters = initial_parameters

    def run_strategy(self, parameters):
        strategy = self.strategy_class(self.data, **parameters)
        strategy.run()
        return strategy.get_results()

    def parameter_sensitivity(self, param_ranges, n_jobs=-1):
        param_combinations = list(product(*param_ranges.values()))
        param_keys = list(param_ranges.keys())

        with ProcessPoolExecutor(max_workers=n_jobs) as executor:
            results = list(executor.map(
                self.run_strategy,
                [dict(zip(param_keys, combo)) for combo in param_combinations]
            ))

        sensitivity_df = pd.DataFrame([
            {**dict(zip(param_keys, combo)), **result}
            for combo, result in zip(param_combinations, results)
        ])

        return sensitivity_df

    def plot_parameter_sensitivity(self, sensitivity_df, metric='sharpe_ratio'):
        fig, axes = plt.subplots(1, len(self.initial_parameters), figsize=(5*len(self.initial_parameters), 5))
        for i, param in enumerate(self.initial_parameters):
            sensitivity_df.plot.scatter(x=param, y=metric, ax=axes[i])
            axes[i].set_title(f'{metric.capitalize()} vs {param}')
        plt.tight_layout()
        plt.show()

    def monte_carlo_simulation(self, n_simulations=1000, noise_level=0.01):
        base_returns = self.data['returns']
        simulated_results = []

        for _ in range(n_simulations):
            noise = np.random.normal(0, noise_level, len(base_returns))
            simulated_returns = base_returns + noise
            simulated_data = self.data.copy()
            simulated_data['returns'] = simulated_returns
            
            strategy = self.strategy_class(simulated_data, **self.initial_parameters)
            strategy.run()
            simulated_results.append(strategy.get_results())

        return pd.DataFrame(simulated_results)

    def plot_monte_carlo_results(self, mc_results, metric='sharpe_ratio'):
        plt.figure(figsize=(10, 6))
        plt.hist(mc_results[metric], bins=50)
        plt.title(f'Distribution of {metric.capitalize()} in Monte Carlo Simulation')
        plt.xlabel(metric.capitalize())
        plt.ylabel('Frequency')
        plt.axvline(mc_results[metric].mean(), color='r', linestyle='dashed', linewidth=2)
        plt.text(mc_results[metric].mean(), plt.ylim()[1]*0.9, 'Mean', rotation=90, va='top')
        plt.show()

    def time_period_analysis(self, period_length=252):
        results = []
        for start in range(0, len(self.data) - period_length, period_length):
            end = start + period_length
            period_data = self.data.iloc[start:end]
            strategy = self.strategy_class(period_data, **self.initial_parameters)
            strategy.run()
            results.append({
                'start_date': period_data.index[0],
                'end_date': period_data.index[-1],
                **strategy.get_results()
            })
        return pd.DataFrame(results)

    def plot_time_period_analysis(self, period_results, metric='sharpe_ratio'):
        plt.figure(figsize=(12, 6))
        plt.plot(period_results['start_date'], period_results[metric])
        plt.title(f'{metric.capitalize()} Over Different Time Periods')
        plt.xlabel('Start Date of Period')
        plt.ylabel(metric.capitalize())
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()

# 使用示例
class SimpleMovingAverageCrossover:
    def __init__(self, data, short_window=50, long_window=200):
        self.data = data
        self.short_window = short_window
        self.long_window = long_window
        self.signals = pd.DataFrame(index=data.index)
        self.positions = pd.DataFrame(index=data.index)
        self.returns = None

    def generate_signals(self):
        self.signals['short_mavg'] = self.data['close'].rolling(window=self.short_window, min_periods=1, center=False).mean()
        self.signals['long_mavg'] = self.data['close'].rolling(window=self.long_window, min_periods=1, center=False).mean()
        self.signals['signal'] = np.where(self.signals['short_mavg'] > self.signals['long_mavg'], 1.0, 0.0)
        self.signals['positions'] = self.signals['signal'].diff()

    def backtest_strategy(self):
        self.positions = self.signals['positions']
        self.returns = self.positions.shift(1) * self.data['returns']
        self.returns = self.returns[self.returns.index >= self.data.index[self.long_window]]

    def run(self):
        self.generate_signals()
        self.backtest_strategy()

    def get_results(self):
        total_return = np.exp(self.returns.sum()) - 1
        sharpe_ratio = np.sqrt(252) * self.returns.mean() / self.returns.std()
        max_drawdown = (self.returns.cumsum() - self.returns.cumsum().cummax()).min()
        return {
            'total_return': total_return,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown
        }

# 生成示例数据
np.random.seed(42)
dates = pd.date_range(start='2010-01-01', end='2020-12-31', freq='D')
prices = pd.Series(np.random.randn(len(dates)).cumsum() + 100, index=dates)
returns = prices.pct_change()
data = pd.DataFrame({'close': prices, 'returns': returns})

# 初始化鲁棒性分析
initial_parameters = {'short_window': 50, 'long_window': 200}
robustness_analysis = RobustnessAnalysis(SimpleMovingAverageCrossover, data, initial_parameters)

# 参数敏感性分析
param_ranges = {
    'short_window': range(10, 100, 10),
    'long_window': range(100, 300, 20)
}
sensitivity_results = robustness_analysis.parameter_sensitivity(param_ranges)
robustness_analysis.plot_parameter_sensitivity(sensitivity_results)

# 蒙特卡洛模拟
mc_results = robustness_analysis.monte_carlo_simulation()
robustness_analysis.plot_monte_carlo_results(mc_results)

# 时间周期分析
period_results = robustness_analysis.time_period_analysis()
robustness_analysis.plot_time_period_analysis(period_results)
```

这个鲁棒性分析模块包含了几个关键组件：

1. 参数敏感性分析：评估策略对不同参数设置的敏感程度。

2. 蒙特卡洛模拟：通过添加随机噪声来模拟不同的市场情景，评估策略的稳定性。

3. 时间周期分析：在不同的时间段上评估策略性能，检查策略是否在所有市场环境中都表现良好。

在实际应用中，你可能还需要考虑以下几点来进一步改进鲁棒性分析：

1. 压力测试：模拟极端市场条件（如金融危机）下的策略表现。

2. 交易成本敏感性：分析不同交易成本水平对策略性能的影响。

3. 数据偏差分析：评估策略对数据质量问题（如缺失数据、异常值）的敏感性。

4. 多资产类别测试：在不同资产类别上测试策略的表现，评估策略的通用性。

5. 滚动优化：实现滚动窗口的参数优化，评估策略参数的稳定性。

6. 样本外测试：使用样本外数据验证策略性能，避免过拟合。

7. 统计显著性检验：对不同参数设置和时间段的结果进行统计显著性检验。

8. 相关性分析：评估策略收益与各种市场因子的相关性，了解策略的风险暴露。

9. 极值理论：应用极值理论来更好地评估尾部风险。

10. 情景分析：设计特定的市场情景（如趋势市场、震荡市场、高波动性市场等），评估策略在这些情景下的表现。

以下是一些额外的鲁棒性分析方法的实现示例：

```python
import scipy.stats as stats
from scipy.stats import norm
from statsmodels.tsa.stattools import adfuller

class AdvancedRobustnessAnalysis(RobustnessAnalysis):
    def __init__(self, strategy_class, data, initial_parameters):
        super().__init__(strategy_class, data, initial_parameters)

    def rolling_optimization(self, window_size=252, step_size=20, param_ranges=None):
        if param_ranges is None:
            param_ranges = {k: [v] for k, v in self.initial_parameters.items()}

        results = []
        for start in range(0, len(self.data) - window_size, step_size):
            end = start + window_size
            window_data = self.data.iloc[start:end]
            
            window_sensitivity = self.parameter_sensitivity(param_ranges, data=window_data)
            best_params = window_sensitivity.loc[window_sensitivity['sharpe_ratio'].idxmax()]
            
            results.append({
                'start_date': window_data.index[0],
                'end_date': window_data.index[-1],
                **{k: best_params[k] for k in self.initial_parameters.keys()},
                'sharpe_ratio': best_params['sharpe_ratio']
            })
        
        return pd.DataFrame(results)

    def plot_rolling_optimization(self, rolling_results):
        fig, axes = plt.subplots(len(self.initial_parameters) + 1, 1, figsize=(12, 4 * (len(self.initial_parameters) + 1)), sharex=True)
        
        for i, param in enumerate(self.initial_parameters.keys()):
            axes[i].plot(rolling_results['start_date'], rolling_results[param])
            axes[i].set_ylabel(param)
            axes[i].set_title(f'Optimal {param} over time')
        
        axes[-1].plot(rolling_results['start_date'], rolling_results['sharpe_ratio'])
        axes[-1].set_ylabel('Sharpe Ratio')
        axes[-1].set_title('Optimal Sharpe Ratio over time')
        
        plt.tight_layout()
        plt.show()

    def extreme_value_analysis(self, returns, threshold_percentile=95):
        threshold = np.percentile(returns, threshold_percentile)
        exceedances = returns[returns > threshold] - threshold
        
        shape, loc, scale = stats.genpareto.fit(exceedances)
        
        var_95 = norm.ppf(0.95, returns.mean(), returns.std())
        var_99 = norm.ppf(0.99, returns.mean(), returns.std())
        
        es_95 = returns[returns > var_95].mean()
        es_99 = returns[returns > var_99].mean()
        
        return {
            'shape': shape,
            'scale': scale,
            'var_95': var_95,
            'var_99': var_99,
            'es_95': es_95,
            'es_99': es_99
        }

    def correlation_analysis(self, strategy_returns, factor_returns):
        correlations = strategy_returns.corr(factor_returns)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        im = ax.imshow(correlations.values, cmap='coolwarm')
        
        ax.set_xticks(np.arange(len(correlations.columns)))
        ax.set_yticks(np.arange(len(correlations.index)))
        ax.set_xticklabels(correlations.columns)
        ax.set_yticklabels(correlations.index)
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")
        
        for i in range(len(correlations.index)):
            for j in range(len(correlations.columns)):
                ax.text(j, i, f"{correlations.iloc[i, j]:.2f}", ha="center", va="center", color="black")
        
        ax.set_title("Correlation between Strategy Returns and Market Factors")
        fig.tight_layout()
        plt.colorbar(im)
        plt.show()

    def stationarity_test(self, returns):
        result = adfuller(returns)
        return {
            'adf_statistic': result[0],
            'p_value': result[1],
            'critical_values': result[4]
        }

# 使用示例
advanced_analysis = AdvancedRobustnessAnalysis(SimpleMovingAverageCrossover, data, initial_parameters)

# 滚动优化
rolling_results = advanced_analysis.rolling_optimization(param_ranges=param_ranges)
advanced_analysis.plot_rolling_optimization(rolling_results)

# 极值分析
strategy = SimpleMovingAverageCrossover(data, **initial_parameters)
strategy.run()
extreme_value_results = advanced_analysis.extreme_value_analysis(strategy.returns)
print("Extreme Value Analysis Results:")
print(extreme_value_results)

# 相关性分析（假设我们有一些市场因子数据）
market_factors = pd.DataFrame({
    'Market': np.random.randn(len(data)),
    'SMB': np.random.randn(len(data)),
    'HML': np.random.randn(len(data)),
    'Momentum': np.random.randn(len(data))
}, index=data.index)
advanced_analysis.correlation_analysis(strategy.returns, market_factors)

# 平稳性检验
stationarity_results = advanced_analysis.stationarity_test(strategy.returns)
print("Stationarity Test Results:")
print(stationarity_results)
```

这些高级鲁棒性分析方法提供了更深入的策略评估：

1. 滚动优化可以帮助我们了解最优参数如何随时间变化，从而评估策略的稳定性。

2. 极值分析使用广义帕累托分布来更准确地估计尾部风险，这对于评估策略在极端市场条件下的表现很有帮助。

3. 相关性分析可以揭示策略收益与各种市场因子之间的关系，帮助我们理解策略的风险来源。

4. 平稳性检验可以帮助我们确定策略收益是否是平稳的，这对于许多统计模型和风险管理技术的应用是重要的前提。

通过结合这些基本和高级的鲁棒性分析方法，我们可以全面评估策略的稳定性、风险特征和适应性。这有助于我们识别策略的潜在弱点，并在实际交易中做出更明智的决策。然而，需要注意的是，即使经过全面的鲁棒性分析，也不能保证策略在未来会表现良好。市场环境总是在变化，持续的监控和调整仍然是必要的。

## 11.5 LLM辅助策略分析

大型语言模型（LLM）可以为量化交易策略的分析提供独特的视角和洞察。以下是一个结合LLM的策略分析模块示例：

```python
import openai
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler

class LLMStrategyAnalyzer:
    def __init__(self, api_key):
        self.api_key = api_key
        openai.api_key = self.api_key

    def get_llm_analysis(self, prompt):
        response = openai.Completion.create(
            engine="text-davinci-002",
            prompt=prompt,
            max_tokens=500,
            n=1,
            stop=None,
            temperature=0.7,
        )
        return response.choices[0].text.strip()

    def analyze_performance_metrics(self, metrics):
        prompt = f"""Analyze the following performance metrics of a trading strategy:

{metrics}

Provide a concise analysis of the strategy's performance, highlighting strengths and potential areas of concern:"""
        
        return self.get_llm_analysis(prompt)

    def analyze_drawdowns(self, drawdowns):
        prompt = f"""Analyze the following drawdown data of a trading strategy:

{drawdowns}

Provide insights on the strategy's risk characteristics and suggest potential improvements:"""
        
        return self.get_llm_analysis(prompt)

    def analyze_trade_distribution(self, trade_stats):
        prompt = f"""Analyze the following trade distribution statistics:

{trade_stats}

Provide insights on the strategy's trading behavior and suggest potential optimizations:"""
        
        return self.get_llm_analysis(prompt)

    def analyze_market_regimes(self, performance_by_regime):
        prompt = f"""Analyze the strategy's performance across different market regimes:

{performance_by_regime}

Provide insights on the strategy's behavior in different market conditions and suggest potential improvements:"""
        
        return self.get_llm_analysis(prompt)

    def generate_report(self, strategy_results):
        performance_analysis = self.analyze_performance_metrics(strategy_results['performance_metrics'])
        drawdown_analysis = self.analyze_drawdowns(strategy_results['drawdowns'])
        trade_analysis = self.analyze_trade_distribution(strategy_results['trade_stats'])
        regime_analysis = self.analyze_market_regimes(strategy_results['performance_by_regime'])

        report = f"""
Strategy Analysis Report

1. Performance Metrics Analysis:
{performance_analysis}

2. Drawdown Analysis:
{drawdown_analysis}

3. Trade Distribution Analysis:
{trade_analysis}

4. Market Regime Analysis:
{regime_analysis}

Overall Conclusion:
Based on the above analyses, here's an overall assessment of the strategy and recommendations for improvement:

{self.get_llm_analysis("Based on the above analyses, provide an overall assessment of the strategy and recommendations for improvement.")}
"""
        return report

# 使用示例
class EnhancedMovingAverageCrossover:
    def __init__(self, data, short_window=50, long_window=200):
        self.data = data
        self.short_window = short_window
        self.long_window = long_window
        self.signals = pd.DataFrame(index=data.index)
        self.positions = pd.DataFrame(index=data.index)
        self.returns = None

    def generate_signals(self):
        self.signals['short_mavg'] = self.data['close'].rolling(window=self.short_window, min_periods=1, center=False).mean()
        self.signals['long_mavg'] = self.data['close'].rolling(window=self.long_window, min_periods=1, center=False).mean()
        self.signals['signal'] = np.where(self.signals['short_mavg'] > self.signals['long_mavg'], 1.0, 0.0)
        self.signals['positions'] = self.signals['signal'].diff()

    def backtest_strategy(self):
        self.positions = self.signals['positions']
        self.returns = self.positions.shift(1) * self.data['returns']
        self.returns = self.returns[self.returns.index >= self.data.index[self.long_window]]

    def run(self):
        self.generate_signals()
        self.backtest_strategy()

    def get_performance_metrics(self):
        total_return = np.exp(self.returns.sum()) - 1
        sharpe_ratio = np.sqrt(252) * self.returns.mean() / self.returns.std()
        sortino_ratio = np.sqrt(252) * self.returns.mean() / self.returns[self.returns < 0].std()
        max_drawdown = (self.returns.cumsum() - self.returns.cumsum().cummax()).min()
        
        return {
            'Total Return': f"{total_return:.2%}",
            'Sharpe Ratio': f"{sharpe_ratio:.2f}",
            'Sortino Ratio': f"{sortino_ratio:.2f}",
            'Max Drawdown': f"{max_drawdown:.2%}"
        }

    def get_drawdowns(self):
        cumulative_returns = (1 + self.returns).cumprod()
        peak = cumulative_returns.cummax()
        drawdowns = (cumulative_returns - peak) / peak
        return drawdowns.sort_values().head()

    def get_trade_stats(self):
        trades = self.positions[self.positions != 0]
        win_rate = (self.returns > 0).mean()
        avg_win = self.returns[self.returns > 0].mean()
        avg_loss = self.returns[self.returns < 0].mean()
        
        return {
            'Number of Trades': len(trades),
            'Win Rate': f"{win_rate:.2%}",
            'Average Win': f"{avg_win:.2%}",
            'Average Loss': f"{avg_loss:.2%}",
            'Profit Factor': f"{abs(avg_win / avg_loss):.2f}"
        }

    def get_performance_by_regime(self):
        volatility = self.data['returns'].rolling(window=21).std() * np.sqrt(252)
        regimes = pd.cut(volatility, bins=3, labels=['Low Vol', 'Medium Vol', 'High Vol'])
        
        performance_by_regime = self.returns.groupby(regimes).agg(['mean', 'std'])
        performance_by_regime['sharpe'] = performance_by_regime['mean'] / performance_by_regime['std'] * np.sqrt(252)
        
        return performance_by_regime

    def get_results(self):
        return {
            'performance_metrics': self.get_performance_metrics(),
            'drawdowns': self.get_drawdowns().to_dict(),
            'trade_stats': self.get_trade_stats(),
            'performance_by_regime': self.get_performance_by_regime().to_dict()
        }

# 生成示例数据
np.random.seed(42)
dates = pd.date_range(start='2010-01-01', end='2020-12-31', freq='D')
prices = pd.Series(np.random.randn(len(dates)).cumsum() + 100, index=dates)
returns = prices.pct_change()
data = pd.DataFrame({'close': prices, 'returns': returns})

# 运行策略
strategy = EnhancedMovingAverageCrossover(data)
strategy.run()
strategy_results = strategy.get_results()

# 使用LLM分析策略
analyzer = LLMStrategyAnalyzer(api_key="your-openai-api-key")
report = analyzer.generate_report(strategy_results)
print(report)
```

这个LLM辅助策略分析模块提供了以下功能：

1. 性能指标分析：评估策略的总体表现，包括收益率、夏普比率等。

2. 回撤分析：分析策略的风险特征，特别是大幅度亏损。

3. 交易分布分析：评估策略的交易行为，包括胜率、平均盈亏等。

4. 市场环境分析：分析策略在不同市场环境（如高波动性、低波动性）下的表现。

5. 综合报告生成：基于以上分析生成全面的策略评估报告。

在实际应用中，你可能还需要考虑以下几点来进一步改进LLM辅助策略分析：

1. 交互式分析：实现一个对话系统，允许分析师与LLM进行交互，深入探讨特定问题。

2. 多策略比较：使用LLM比较多个策略的优劣，并提供综合建议。

3. 异常检测：利用LLM识别和解释策略表现中的异常模式。

4. 市场洞察整合：结合外部市场数据和新闻，提供更全面的策略环境分析。

5. 参数优化建议：基于策略表现，让LLM提供参数调整的建议。

6. 风险预警：设计LLM驱动的风险预警系统，及时发现潜在问题。

7. 策略改进建议：利用LLM的创造力，为策略改进提供创新ideas。

8. 代码审查：使用LLM分析策略代码，提供优化和错误检测建议。

9. 回测偏差分析：让LLM帮助识别和解释可能的回测偏差。

10. 可解释性增强：使用LLM来解释复杂的机器学习模型决策。

以下是一些额外的LLM辅助分析功能的实现示例：

```python
class AdvancedLLMStrategyAnalyzer(LLMStrategyAnalyzer):
    def __init__(self, api_key):
        super().__init__(api_key)

    def interactive_analysis(self, strategy_results):
        print("Welcome to the interactive strategy analysis session.")
        print("You can ask questions about the strategy's performance.")
        print("Type 'exit' to end the session.")

        while True:
            question = input("\nYour question: ")
            if question.lower() == 'exit':
                break

            prompt = f"""Given the following strategy results:

{strategy_results}

Answer the following question about the strategy:
{question}"""

            answer = self.get_llm_analysis(prompt)
            print(f"\nAnalysis: {answer}")

    def compare_strategies(self, strategies_results):
        strategies_summary = "\n".join([f"Strategy {i+1}: {res['performance_metrics']}" for i, res in enumerate(strategies_results)])
        
        prompt = f"""Compare the following trading strategies based on their performance metrics:

{strategies_summary}

Provide a comprehensive comparison, highlighting the strengths and weaknesses of each strategy:"""

        return self.get_llm_analysis(prompt)

    def detect_anomalies(self, returns, window_size=20):
        rolling_mean = returns.rolling(window=window_size).mean()
        rolling_std = returns.rolling(window=window_size).std()
        z_scores = (returns - rolling_mean) / rolling_std
        anomalies = z_scores[abs(z_scores) > 3]

        if len(anomalies) > 0:
            anomalies_data = anomalies.to_dict()
            prompt = f"""Analyze the following anomalies detected in the strategy's returns:

{anomalies_data}

Provide insights on these anomalies and their potential impact on the strategy:"""

            return self.get_llm_analysis(prompt)
        else:
            return "No significant anomalies detected in the strategy's returns."

    def generate_improvement_ideas(self, strategy_results):
        prompt = f"""Based on the following strategy results:

{strategy_results}

Generate innovative ideas to improve the strategy's performance. Consider aspects such as:
1. Risk management
2. Entry and exit timing
3. Asset selection
4. Market regime adaptation
5. Alternative data sources

Provide 3-5 concrete improvement suggestions:"""

        return self.get_llm_analysis(prompt)

# 使用示例
advanced_analyzer = AdvancedLLMStrategyAnalyzer(api_key="your-openai-api-key")

# 交互式分析
advanced_analyzer.interactive_analysis(strategy_results)

# 多策略比较
strategy2 = EnhancedMovingAverageCrossover(data, short_window=20, long_window=100)
strategy2.run()
strategy2_results = strategy2.get_results()

comparison = advanced_analyzer.compare_strategies([strategy_results, strategy2_results])
print("\nStrategy Comparison:")
print(comparison)

# 异常检测
anomaly_analysis = advanced_analyzer.detect_anomalies(strategy.returns)
print("\nAnomaly Analysis:")
print(anomaly_analysis)

# 策略改进建议
improvement_ideas = advanced_analyzer.generate_improvement_ideas(strategy_results)
print("\nStrategy Improvement Ideas:")
print(improvement_ideas)
```

这些高级LLM辅助分析功能提供了更深入和互动的策略评估：

1. 交互式分析允许分析师根据具体需求深入探讨策略的各个方面。

2. 多策略比较有助于选择最佳策略或组合多个策略。

3. 异常检测可以帮助识别潜在的风险或机会。

4. 策略改进建议利用了LLM的创造力，可能会产生创新的优化方向。

通过结合这些基本和高级的LLM辅助分析方法，我们可以获得更全面、更深入的策略评估。LLM不仅可以处理大量数据和复杂的分析任务，还可以提供类似人类专家的洞察和建议。这种方法可以显著提高策略分析的效率和质量，帮助交易者做出更明智的决策。

然而，需要注意的是，LLM的输出应该被视为辅助工具，而不是最终决策的唯一依据。人类专家的判断、市场经验和直觉仍然是不可或缺的。此外，持续监控LLM的输出质量，并根据实际市场表现调整和改进分析流程也是很重要的。

结合传统的定量分析方法和LLM辅助分析，我们可以构建一个更强大、更全面的策略评估框架，为量化交易策略的开发和优化提供有力支持。
